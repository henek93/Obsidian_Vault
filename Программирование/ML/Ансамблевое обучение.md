Ансамблевое обучение - объединение моделей. Ансамблевое обучение помогает моделям не переобучаться.
![[Pasted image 20250925082710.png]]
Два вида основныз ансамблей:
![[Pasted image 20250925082738.png]]
# Бэггинг
Один из самых популярных моделей бэггинга это случайный лес.
Для этого мы разьиваем исходные данные, и для каждого кусочка обучем дерево решений.
![[Pasted image 20250925091330.png]]
После разбиения и обучения мы объединяем их путем голосования. И выбираем классификацию изъодя из того как много моделей сказали что это 0 или 1.
![[Pasted image 20250925091453.png]]
# AdaBoost - adaptive boosting
Мы также объединяем слабые модлеи в один сильный. Разница тольок в том, что мы делаем это боллее осознанно. Новые модели строятся на основе старых и закрывают их слабости.
Мы присваеваем каждой точке вес 1 и обчуаем слабый алгоритм(дерево решений с глубиной 1), после этого мы считаем коэффициент масштабирования(кол. правильно классифицированных точек на неправильно классифицированных точек) и изменяем вес неправильно классифицированных точек.
![[Pasted image 20250925093454.png]]
Потом повторяем эту процедуру.
![[Pasted image 20250925093740.png]]
### Коэффициент масштабирования - это отношение между суммами весов правильно и неправильно классифицированных точек
Процесс обчуния слабых алгоритмов продолжается сколько потребуется.
Суть AdaBoosting как раз заключается в том, чтобы объединить все эти слабые модели в один сильный, но сделать это нужно так, чтобы плохти моделям меньше доверяли, а хорошим больше.
Вот свойства этого числа коэффициента:
![[Pasted image 20250925094811.png]]

