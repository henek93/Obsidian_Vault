Недообучение слуяается, когда модлеь слишком слабая для набора данных и не может их всех охватить
Переобучени это обратный случай, модель слишком сложна для данных из-за чего теряется суть и произсводительность.
![[Pasted image 20250911120825.png]]
В данном случае лучше подходит модель 2, потому что суть задачи в том что данные располагаются паралболой вних, а модель 3 просто запомнила и прозодится по всем обучающим точкам, но если появятся новый точки, то она не справится, потому тчо не поняла суть задачи.
### Что используют для решения проблемы
Для решения проблемы используют тестовую и обучающуб выборку. Например было 100 вопрос, 80 дали для обучения модели, а 20 для проверки как  она их переработал и вернали моель вообще
![[Pasted image 20250911121706.png]]
![[Pasted image 20250911121813.png]]

### Как правильно разбивать данные
Данные правильно разбивать на:
1) Обучающую выборку - для обучения
2) Контрольный набор - для выбора правильной модеи
3) Тестовый набор - для проверки того на сколько хорошо модель справилась

Один из хороших способов определить подходящую модель это построить гаффик
![[Pasted image 20250911123528.png]]
### Регуляризация
Суть в том тчобы не обучать нескоьлок моделей срузу и выбирать потом лучшую, а обучать одну модель и походу дела оптимизировать ее производительность и сложность.
Есть 2 способа измерения сложность модели: 
1) L1 - сумма абсолютных значение коэффициентов
2) L2 - сумма квадратов коэффиецентов
![[Pasted image 20250911125351.png]]
Величина которую нужно свести к минимуму, это модифицированная ошибка, определяемая как сумма двух слагаемых 
$$
ошибка = ошибкарегрессии + слагаемое регуляризации
$$
> Немного терминологи
> Если мы обучем модлеь и используем L1  - регрессия Лассо
> Если мы обчуаем модель и используем L2 - гребневая регрессия

### Отличае L1 от L2
![[Pasted image 20250911130818.png]]

## Гиперпараметр параметр регуляризации
Его цель в том, чтобы понять на что ориентироваться при построении модели на производительность или простоу.
Параметр регуляризации обозначается $\lambda$ 
Новая формула ошибки выглядит вот так
$$
ошибка = ошибкарегрессии + \lambda * слагаемое регуляризации
$$
![[Pasted image 20250911131610.png]]
