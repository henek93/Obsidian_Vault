# üìê –ú–∞—Ç–µ–º–∞—Ç–∏–∫–∞ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π

> **–ü–æ–ª–Ω—ã–π —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ—Å–Ω–æ–≤–∞–º –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π**

–≠—Ç–æ—Ç —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏, –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.

## üìä –õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞

### üî¢ –ú–∞—Ç—Ä–∏—Ü—ã –∏ –≤–µ–∫—Ç–æ—Ä—ã

**–û—Å–Ω–æ–≤–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:**

**–í–µ–∫—Ç–æ—Ä** ‚Äî —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —á–∏—Å–µ–ª:
$$\mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{bmatrix}$$

**–ü—Ä–∏–º–µ—Ä –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –¥–æ–º–∞:**
$$\mathbf{house} = \begin{bmatrix} 150 \\ 3 \\ 2 \\ 20 \end{bmatrix} \text{ (–ø–ª–æ—â–∞–¥—å, –∫–æ–º–Ω–∞—Ç—ã, —ç—Ç–∞–∂–∏, –≤–æ–∑—Ä–∞—Å—Ç)}$$

**–ú–∞—Ç—Ä–∏—Ü–∞** ‚Äî –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —á–∏—Å–µ–ª:
$$\mathbf{A} = \begin{bmatrix} 
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix}$$

**–ü—Ä–∏–º–µ—Ä –º–∞—Ç—Ä–∏—Ü—ã –¥–∞–Ω–Ω—ã—Ö (3 –¥–æ–º–∞, 4 –ø—Ä–∏–∑–Ω–∞–∫–∞):**
$$\mathbf{X} = \begin{bmatrix}
150 & 3 & 2 & 20 \\
200 & 4 & 1 & 5 \\
80 & 2 & 1 & 15
\end{bmatrix}$$

**–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏:**
- –í–µ–∫—Ç–æ—Ä: $\mathbf{x} \in \mathbb{R}^n$ (n —ç–ª–µ–º–µ–Ω—Ç–æ–≤)
- –ú–∞—Ç—Ä–∏—Ü–∞: $\mathbf{A} \in \mathbb{R}^{m \times n}$ (m —Å—Ç—Ä–æ–∫, n —Å—Ç–æ–ª–±—Ü–æ–≤)
- –í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö: –≤—Ö–æ–¥—ã —á–∞—Å—Ç–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –∫–∞–∫ –≤–µ–∫—Ç–æ—Ä—ã, –≤–µ—Å–∞ –∫–∞–∫ –º–∞—Ç—Ä–∏—Ü—ã

### ‚ûï –û–ø–µ—Ä–∞—Ü–∏–∏ —Å –º–∞—Ç—Ä–∏—Ü–∞–º–∏

**–°–ª–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü:**
$$(\mathbf{A} + \mathbf{B})_{ij} = a_{ij} + b_{ij}$$

**–ü—Ä–∏–º–µ—Ä:**
$$\begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} + \begin{bmatrix} 5 & 6 \\ 7 & 8 \end{bmatrix} = \begin{bmatrix} 6 & 8 \\ 10 & 12 \end{bmatrix}$$

**–£–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –Ω–∞ —Å–∫–∞–ª—è—Ä:**
$$(\alpha \mathbf{A})_{ij} = \alpha \cdot a_{ij}$$

**–ü—Ä–∏–º–µ—Ä:**
$$3 \cdot \begin{bmatrix} 1 & 2 \\ 3 & 4 \end{bmatrix} = \begin{bmatrix} 3 & 6 \\ 9 & 12 \end{bmatrix}$$

**–£–º–Ω–æ–∂–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü:**
$$(\mathbf{AB})_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}$$

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**
$$\mathbf{A} = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix}_{2 \times 3}, \quad \mathbf{B} = \begin{bmatrix} 7 & 8 \\ 9 & 10 \\ 11 & 12 \end{bmatrix}_{3 \times 2}$$

$$\mathbf{AB} = \begin{bmatrix} 1 \cdot 7 + 2 \cdot 9 + 3 \cdot 11 & 1 \cdot 8 + 2 \cdot 10 + 3 \cdot 12 \\ 4 \cdot 7 + 5 \cdot 9 + 6 \cdot 11 & 4 \cdot 8 + 5 \cdot 10 + 6 \cdot 12 \end{bmatrix}$$

$$= \begin{bmatrix} 7 + 18 + 33 & 8 + 20 + 36 \\ 28 + 45 + 66 & 32 + 50 + 72 \end{bmatrix} = \begin{bmatrix} 58 & 64 \\ 139 & 154 \end{bmatrix}_{2 \times 2}$$

**–í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö:** —ç—Ç–æ –æ–ø–µ—Ä–∞—Ü–∏—è –≤—Ö–æ–¥—ã √ó –≤–µ—Å–∞

**–¢—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ:**
$$(\mathbf{A}^T)_{ij} = a_{ji}$$

**–ü—Ä–∏–º–µ—Ä:**
$$\mathbf{A} = \begin{bmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \end{bmatrix} \Rightarrow \mathbf{A}^T = \begin{bmatrix} 1 & 4 \\ 2 & 5 \\ 3 & 6 \end{bmatrix}$$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ Python:**
```
import numpy as np

# –ú–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤ (3 –Ω–µ–π—Ä–æ–Ω–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º —Å–ª–æ–µ, 4 –≤—Ö–æ–¥–∞)
W = np.array([[0.1, 0.2, 0.3, 0.4],
              [0.5, 0.6, 0.7, 0.8], 
              [0.9, 1.0, 1.1, 1.2]])

# –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
x = np.array([1, 2, 3, 4])

# –õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
z = W @ x  # —Ä–∞–≤–Ω–æ—Å–∏–ª—å–Ω–æ np.dot(W, x)
print(z)  # [3.0, 7.0, 11.0]
```

### üéØ –°–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ

**–î–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤:**
$$\mathbf{x} \cdot \mathbf{y} = \mathbf{x}^T \mathbf{y} = \sum_{i=1}^{n} x_i y_i$$

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**
$$\mathbf{x} = \begin{bmatrix} 2 \\ 3 \\ 4 \end{bmatrix}, \quad \mathbf{y} = \begin{bmatrix} 1 \\ 5 \\ 2 \end{bmatrix}$$

$$\mathbf{x} \cdot \mathbf{y} = 2 \cdot 1 + 3 \cdot 5 + 4 \cdot 2 = 2 + 15 + 8 = 25$$

**–ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
$$\mathbf{x} \cdot \mathbf{y} = ||\mathbf{x}|| \cdot ||\mathbf{y}|| \cdot \cos(\theta)$$

–≥–¥–µ $\theta$ ‚Äî —É–≥–æ–ª –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏.

**–ù–æ—Ä–º–∞ –≤–µ–∫—Ç–æ—Ä–∞ (L2 –Ω–æ—Ä–º–∞):**
$$||\mathbf{x}||_2 = \sqrt{\sum_{i=1}^{n} x_i^2}$$

**–ü—Ä–∏–º–µ—Ä:**
$$||\mathbf{x}||_2 = \sqrt{2^2 + 3^2 + 4^2} = \sqrt{4 + 9 + 16} = \sqrt{29} \approx 5.39$$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
```python
# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–∞–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
user_profile = np.array([1, 0, 1, 1, 0])  # –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
movie_features = np.array([1, 1, 1, 0, 0])  # –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ñ–∏–ª—å–º–∞

similarity = np.dot(user_profile, movie_features)
print(f"–°—Ö–æ–¥—Å—Ç–≤–æ: {similarity}")  # 2

# –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è —Å—Ö–æ–¥—Å—Ç—å (–∫–æ—Å–∏–Ω—É—Å–Ω–∞—è)
norm_similarity = similarity / (np.linalg.norm(user_profile) * np.linalg.norm(movie_features))
print(f"–ö–æ—Å–∏–Ω—É—Å–Ω–∞—è —Å—Ö–æ–¥—Å—Ç—å: {norm_similarity:.3f}")
```

**–í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö:**
- –õ–∏–Ω–µ–π–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ: $z = \mathbf{w}^T \mathbf{x} + b$
- –ê—Ç—Ç–µ–Ω—à–µ–Ω –º–µ—Ö–∞–Ω–∏–∑–º—ã: —Å–∫–∞–ª—è—Ä–Ω–æ–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≤–µ—Å–æ–≤

### üîÑ –û–±—Ä–∞—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞

**–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**
$$\mathbf{A} \mathbf{A}^{-1} = \mathbf{A}^{-1} \mathbf{A} = \mathbf{I}$$

**–ü—Ä–∏–º–µ—Ä –¥–ª—è –º–∞—Ç—Ä–∏—Ü—ã 2x2:**
$$\mathbf{A} = \begin{bmatrix} 4 & 7 \\ 2 & 6 \end{bmatrix}$$

**–û–ø—Ä–µ–¥–µ–ª–∏—Ç–µ–ª—å:**
$$\det(\mathbf{A}) = 4 \cdot 6 - 7 \cdot 2 = 24 - 14 = 10$$

**–û–±—Ä–∞—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞:**
$$\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{bmatrix} 6 & -7 \\ -2 & 4 \end{bmatrix} = \frac{1}{10} \begin{bmatrix} 6 & -7 \\ -2 & 4 \end{bmatrix} = \begin{bmatrix} 0.6 & -0.7 \\ -0.2 & 0.4 \end{bmatrix}$$

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
$$\mathbf{A} \mathbf{A}^{-1} = \begin{bmatrix} 4 & 7 \\ 2 & 6 \end{bmatrix} \begin{bmatrix} 0.6 & -0.7 \\ -0.2 & 0.4 \end{bmatrix} = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$$

**–°–≤–æ–π—Å—Ç–≤–∞:**
- $(\mathbf{AB})^{-1} = \mathbf{B}^{-1}\mathbf{A}^{-1}$ (–ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞—â–∞–µ—Ç—Å—è!)
- $(\mathbf{A}^T)^{-1} = (\mathbf{A}^{-1})^T$
- $(\mathbf{A}^{-1})^{-1} = \mathbf{A}$

**–ü—Å–µ–≤–¥–æ–æ–±—Ä–∞—Ç–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ (Moore-Penrose):**
–î–ª—è –Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü –∏–ª–∏ —Å–∏–Ω–≥—É–ª—è—Ä–Ω—ã—Ö –º–∞—Ç—Ä–∏—Ü:
$$\mathbf{A}^+ = (\mathbf{A}^T\mathbf{A})^{-1}\mathbf{A}^T \quad \text{(–µ—Å–ª–∏ } \mathbf{A} \text{ –∏–º–µ–µ—Ç –ø–æ–ª–Ω—ã–π —Ä–∞–Ω–≥ –ø–æ —Å—Ç–æ–ª–±—Ü–∞–º})$$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ:**
```
import numpy as np

# –†–µ—à–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ª–∏–Ω–µ–π–Ω—ã—Ö —É—Ä–∞–≤–Ω–µ–Ω–∏–π: Ax = b
A = np.array([[4, 7], [2, 6]])
b = np.array([1, 2])

# –ú–µ—Ç–æ–¥ 1: —á–µ—Ä–µ–∑ –æ–±—Ä–∞—Ç–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É
A_inv = np.linalg.inv(A)
x = A_inv @ b
print(f"–†–µ—à–µ–Ω–∏–µ: {x}")  # [-2.6  2.2]

# –ú–µ—Ç–æ–¥ 2: —á–µ—Ä–µ–∑ –ø—Å–µ–≤–¥–æ–æ–±—Ä–∞—Ç–Ω—É—é –º–∞—Ç—Ä–∏—Ü—É (–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ)
x_pinv = np.linalg.pinv(A) @ b
print(f"–†–µ—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ pinv: {x_pinv}")

# –ú–µ—Ç–æ–¥ 3: –Ω–∞–∏–±–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–π
x_solve = np.linalg.solve(A, b)
print(f"–†–µ—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ solve: {x_solve}")
```

**–í –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏:**
- –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è: $\mathbf{w} = (\mathbf{X}^T\mathbf{X})^{-1}\mathbf{X}^T\mathbf{y}$
- –ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã—Ö –≤–µ—Å–æ–≤

## üìà –ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑

### üî∫ –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π

**–°—Ç–µ–ø–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è:**
$$\frac{d}{dx}(x^n) = nx^{n-1}$$

**–ü—Ä–∏–º–µ—Ä—ã:**
- $\frac{d}{dx}(x^2) = 2x$
- $\frac{d}{dx}(x^3) = 3x^2$
- $\frac{d}{dx}(x^{-1}) = -x^{-2} = -\frac{1}{x^2}$
- $\frac{d}{dx}(\sqrt{x}) = \frac{d}{dx}(x^{1/2}) = \frac{1}{2}x^{-1/2} = \frac{1}{2\sqrt{x}}$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä:** –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å $L(w) = w^2$:
$$\frac{dL}{dw} = 2w$$
–ï—Å–ª–∏ $w = 3$, —Ç–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç —Ä–∞–≤–µ–Ω $6$.

**–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è:**
$$\frac{d}{dx}(e^x) = e^x$$

**–£–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ–µ —Å–≤–æ–π—Å—Ç–≤–æ:** —Ñ—É–Ω–∫—Ü–∏—è —è–≤–ª—è–µ—Ç—Å—è —Å–≤–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π!

**–ü—Ä–∏–º–µ—Ä—ã:**
- $\frac{d}{dx}(e^{2x}) = 2e^{2x}$ (–ø—Ä–∞–≤–∏–ª–æ —Ü–µ–ø–æ—á–∫–∏)
- $\frac{d}{dx}(e^{-x}) = -e^{-x}$
- $\frac{d}{dx}(e^{x^2}) = 2xe^{x^2}$

**–î–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ –æ—Å–Ω–æ–≤–∞–Ω–∏—è:**
$$\frac{d}{dx}(a^x) = a^x \ln(a)$$

**–ù–∞—Ç—É—Ä–∞–ª—å–Ω—ã–π –ª–æ–≥–∞—Ä–∏—Ñ–º:**
$$\frac{d}{dx}(\ln x) = \frac{1}{x}$$

**–ü—Ä–∏–º–µ—Ä—ã:**
- $\frac{d}{dx}(\ln(2x)) = \frac{1}{2x} \cdot 2 = \frac{1}{x}$
- $\frac{d}{dx}(\ln(x^2)) = \frac{1}{x^2} \cdot 2x = \frac{2}{x}$
- $\frac{d}{dx}(\ln(e^x)) = \frac{1}{e^x} \cdot e^x = 1$

**–î–ª—è –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ –æ—Å–Ω–æ–≤–∞–Ω–∏—è:**
$$\frac{d}{dx}(\log_a x) = \frac{1}{x \ln a}$$

**–¢—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
$$\frac{d}{dx}(\sin x) = \cos x$$
$$\frac{d}{dx}(\cos x) = -\sin x$$
$$\frac{d}{dx}(\tan x) = \sec^2 x = \frac{1}{\cos^2 x}$$

**–ü—Ä–∏–º–µ—Ä—ã:**
- $\frac{d}{dx}(\sin(2x)) = 2\cos(2x)$
- $\frac{d}{dx}(\cos(x^2)) = -\sin(x^2) \cdot 2x = -2x\sin(x^2)$

**–û–±—Ä–∞—Ç–Ω—ã–µ —Ç—Ä–∏–≥–æ–Ω–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
- $\frac{d}{dx}(\arcsin x) = \frac{1}{\sqrt{1-x^2}}$
- $\frac{d}{dx}(\arccos x) = -\frac{1}{\sqrt{1-x^2}}$
- $\frac{d}{dx}(\arctan x) = \frac{1}{1+x^2}$

### ‚õìÔ∏è –ü—Ä–∞–≤–∏–ª–∞ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏—è

**–ü—Ä–∞–≤–∏–ª–æ —Å—É–º–º—ã:**
$$\frac{d}{dx}[f(x) + g(x)] = f'(x) + g'(x)$$

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**
–ü—É—Å—Ç—å $h(x) = x^3 + 2x^2 + 5x + 1$
$$h'(x) = \frac{d}{dx}(x^3) + \frac{d}{dx}(2x^2) + \frac{d}{dx}(5x) + \frac{d}{dx}(1)$$
$$= 3x^2 + 4x + 5 + 0 = 3x^2 + 4x + 5$$

**–ü—Ä–∞–≤–∏–ª–æ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è:**
$$\frac{d}{dx}[f(x) \cdot g(x)] = f'(x)g(x) + f(x)g'(x)$$

**–ü—Ä–∏–º–µ—Ä:** $h(x) = x^2 \cdot e^x$
- $f(x) = x^2$, $f'(x) = 2x$
- $g(x) = e^x$, $g'(x) = e^x$

$$h'(x) = 2x \cdot e^x + x^2 \cdot e^x = e^x(2x + x^2) = x e^x(2 + x)$$

**–ú–Ω–µ–º–æ–Ω–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–∏–ª–æ:** "–ø–µ—Ä–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –≤—Ç–æ—Ä–æ–π –ø–ª—é—Å –ø–µ—Ä–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –≤—Ç–æ—Ä–æ–π"

**–ü—Ä–∞–≤–∏–ª–æ —á–∞—Å—Ç–Ω–æ–≥–æ:**
$$\frac{d}{dx}\left[\frac{f(x)}{g(x)}\right] = \frac{f'(x)g(x) - f(x)g'(x)}{[g(x)]^2}$$

**–ü—Ä–∏–º–µ—Ä:** $h(x) = \frac{x^2}{x+1}$
- $f(x) = x^2$, $f'(x) = 2x$
- $g(x) = x+1$, $g'(x) = 1$

$$h'(x) = \frac{2x(x+1) - x^2 \cdot 1}{(x+1)^2} = \frac{2x^2 + 2x - x^2}{(x+1)^2} = \frac{x^2 + 2x}{(x+1)^2} = \frac{x(x + 2)}{(x+1)^2}$$

**–ú–Ω–µ–º–æ–Ω–∏—á–µ—Å–∫–æ–µ –ø—Ä–∞–≤–∏–ª–æ:** "–Ω–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –≤–µ—Ä—Ö–∞ –º–∏–Ω—É—Å –≤–µ—Ä—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –Ω–∏–∑–∞, –≤—Å—ë –Ω–∞ –Ω–∏–∑ –≤ –∫–≤–∞–¥—Ä–∞—Ç–µ"

**–ü—Ä–∞–≤–∏–ª–æ —Ü–µ–ø–æ—á–∫–∏ (—Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π!):**
$$\frac{d}{dx}[f(g(x))] = f'(g(x)) \cdot g'(x)$$

**–ü—Ä–∏–º–µ—Ä—ã:**
1. $h(x) = (x^2 + 1)^3$
   - –í–Ω–µ—à–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è: $f(u) = u^3$, $f'(u) = 3u^2$
   - –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è —Ñ—É–Ω–∫—Ü–∏—è: $g(x) = x^2 + 1$, $g'(x) = 2x$
   $$h'(x) = 3(x^2 + 1)^2 \cdot 2x = 6x(x^2 + 1)^2$$

2. $h(x) = e^{x^2}$
   - –í–Ω–µ—à–Ω—è—è: $f(u) = e^u$, $f'(u) = e^u$
   - –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è: $g(x) = x^2$, $g'(x) = 2x$
   $$h'(x) = e^{x^2} \cdot 2x = 2xe^{x^2}$$

3. $h(x) = \ln(\sin(x))$
   - –í–Ω–µ—à–Ω—è—è: $f(u) = \ln(u)$, $f'(u) = \frac{1}{u}$
   - –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è: $g(x) = \sin(x)$, $g'(x) = \cos(x)$
   $$h'(x) = \frac{1}{\sin(x)} \cdot \cos(x) = \frac{\cos(x)}{\sin(x)} = \cot(x)$$

**–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è —Ü–µ–ø–æ—á–∫–∞:**
–î–ª—è $h(x) = f(g(k(x)))$:
$$h'(x) = f'(g(k(x))) \cdot g'(k(x)) \cdot k'(x)$$

**–ü—Ä–∏–º–µ—Ä:** $h(x) = e^{\sin(x^2)}$
- $f(u) = e^u$, $f'(u) = e^u$
- $g(v) = \sin(v)$, $g'(v) = \cos(v)$
- $k(x) = x^2$, $k'(x) = 2x$

$$h'(x) = e^{\sin(x^2)} \cdot \cos(x^2) \cdot 2x = 2xe^{\sin(x^2)}\cos(x^2)$$

**–í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö:**
–ü—Ä–∞–≤–∏–ª–æ —Ü–µ–ø–æ—á–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ —Å–ª–æ–∏:
$$\frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial a_3} \cdot \frac{\partial a_3}{\partial z_3} \cdot \frac{\partial z_3}{\partial a_2} \cdot \frac{\partial a_2}{\partial z_2} \cdot \frac{\partial z_2}{\partial w_1}$$

### üé≤ –ß–∞—Å—Ç–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ

**–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**
$$\frac{\partial f}{\partial x} = \lim_{h \to 0} \frac{f(x+h, y) - f(x, y)}{h}$$

**–ü—Ä–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–∏ —á–∞—Å—Ç–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π –ø–æ $x$, –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —Å—á–∏—Ç–∞—é—Ç—Å—è –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞–º–∏.**

**–ü–æ–¥—Ä–æ–±–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã:**

1. **–ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä:** $f(x, y) = x^2 + 3xy + y^2$
   
   $$\frac{\partial f}{\partial x} = 2x + 3y + 0 = 2x + 3y$$
   $$\frac{\partial f}{\partial y} = 0 + 3x + 2y = 3x + 2y$$
   
   –ü—Ä–∏ $x = 2, y = 1$:
   - $\frac{\partial f}{\partial x} = 2(2) + 3(1) = 7$
   - $\frac{\partial f}{\partial y} = 3(2) + 2(1) = 8$

2. **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å MSE:** $L(w_1, w_2) = \frac{1}{2}[(w_1x_1 + w_2x_2 - y)^2]$
   
   –û–±–æ–∑–Ω–∞—á–∏–º $u = w_1x_1 + w_2x_2 - y$, —Ç–æ–≥–¥–∞ $L = \frac{1}{2}u^2$
   
   $$\frac{\partial L}{\partial w_1} = \frac{\partial L}{\partial u} \cdot \frac{\partial u}{\partial w_1} = u \cdot x_1 = (w_1x_1 + w_2x_2 - y) \cdot x_1$$
   $$\frac{\partial L}{\partial w_2} = \frac{\partial L}{\partial u} \cdot \frac{\partial u}{\partial w_2} = u \cdot x_2 = (w_1x_1 + w_2x_2 - y) \cdot x_2$$

3. **–°–∏–≥–º–æ–∏–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è:** $f(x, y) = \frac{1}{1 + e^{-(wx + by)}}$
   
   –û–±–æ–∑–Ω–∞—á–∏–º $z = wx + by$, —Ç–æ–≥–¥–∞ $f = \sigma(z) = \frac{1}{1 + e^{-z}}$
   
   $$\frac{\partial f}{\partial w} = \frac{\partial \sigma}{\partial z} \cdot \frac{\partial z}{\partial w} = \sigma(z)(1-\sigma(z)) \cdot x$$
   $$\frac{\partial f}{\partial b} = \frac{\partial \sigma}{\partial z} \cdot \frac{\partial z}{\partial b} = \sigma(z)(1-\sigma(z)) \cdot 1$$

**–ì—Ä–∞–¥–∏–µ–Ω—Ç:**
$$\nabla f = \begin{bmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{bmatrix}$$

**–ì—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞–∏–±–æ–ª—å—à–µ–≥–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏.**

**–ü—Ä–∏–º–µ—Ä:** $f(x, y) = x^2 + y^2$ (–ø–∞—Ä–∞–±–æ–ª–æ–∏–¥)
$$\nabla f = \begin{bmatrix} 2x \\ 2y \end{bmatrix}$$

–í —Ç–æ—á–∫–µ $(3, 4)$: $\nabla f = \begin{bmatrix} 6 \\ 8 \end{bmatrix}$

–ù–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞: $||\nabla f|| = \sqrt{6^2 + 8^2} = \sqrt{100} = 10$

–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (–µ–¥–∏–Ω–∏—á–Ω—ã–π –≤–µ–∫—Ç–æ—Ä): $\frac{\nabla f}{||\nabla f||} = \begin{bmatrix} 0.6 \\ 0.8 \end{bmatrix}$

**–ú–∞—Ç—Ä–∏—Ü–∞ –ì–µ—Å—Å–µ (–≤—Ç–æ—Ä—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ):**
$$H = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \cdots \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \cdots \\
\vdots & \vdots & \ddots
\end{bmatrix}$$

**–ü—Ä–∏–º–µ—Ä:** $f(x, y) = x^3 + xy^2 + y^3$

–ü–µ—Ä–≤—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ:
- $\frac{\partial f}{\partial x} = 3x^2 + y^2$
- $\frac{\partial f}{\partial y} = 2xy + 3y^2$

–í—Ç–æ—Ä—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ:
- $\frac{\partial^2 f}{\partial x^2} = 6x$
- $\frac{\partial^2 f}{\partial y^2} = 2x + 6y$
- $\frac{\partial^2 f}{\partial x \partial y} = \frac{\partial^2 f}{\partial y \partial x} = 2y$

–ú–∞—Ç—Ä–∏—Ü–∞ –ì–µ—Å—Å–µ:
$$H = \begin{bmatrix} 6x & 2y \\ 2y & 2x + 6y \end{bmatrix}$$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã –Ω–∞ Python:**
```
import numpy as np
from scipy.optimize import minimize

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏
def f(vars):
    x, y = vars
    return x**2 + y**2 + x*y

# –ì—Ä–∞–¥–∏–µ–Ω—Ç (–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏)
def gradient(vars):
    x, y = vars
    df_dx = 2*x + y
    df_dy = 2*y + x
    return np.array([df_dx, df_dy])

# –ú–∞—Ç—Ä–∏—Ü–∞ –ì–µ—Å—Å–µ
def hessian(vars):
    x, y = vars
    return np.array([[2, 1], [1, 2]])

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
result = minimize(f, [1, 1], method='BFGS', jac=gradient)
print(f"–ú–∏–Ω–∏–º—É–º: {result.x}")
print(f"–ó–Ω–∞—á–µ–Ω–∏–µ: {result.fun}")
```

**–í –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö:**
–ß–∞—Å—Ç–Ω—ã–µ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è:
- –í—ã—á–∏—Å–ª–µ–Ω–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø–æ –≤–µ—Å–∞–º $\frac{\partial L}{\partial w_{ij}}$
- –ê–ª–≥–æ—Ä–∏—Ç–º–∞ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–µ—Ç–∏

## üßÆ –§—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –∏ –∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ

### üî¢ –°–∏–≥–º–æ–∏–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è

**–§—É–Ω–∫—Ü–∏—è:**
$$\sigma(x) = \frac{1}{1 + e^{-x}}$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\sigma'(x) = \sigma(x)(1 - \sigma(x))$$

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π:**
–ü—É—Å—Ç—å $\sigma(x) = \frac{1}{1 + e^{-x}} = (1 + e^{-x})^{-1}$

–ü–æ –ø—Ä–∞–≤–∏–ª—É —Ü–µ–ø–æ—á–∫–∏:
$$\frac{d\sigma}{dx} = -1 \cdot (1 + e^{-x})^{-2} \cdot (-e^{-x}) = \frac{e^{-x}}{(1 + e^{-x})^2}$$

–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º:
$$\frac{e^{-x}}{(1 + e^{-x})^2} = \frac{1}{1 + e^{-x}} \cdot \frac{e^{-x}}{1 + e^{-x}} = \sigma(x) \cdot \frac{e^{-x}}{1 + e^{-x}}$$

–ó–∞–º–µ—Ç–∏–º, —á—Ç–æ:
$$\frac{e^{-x}}{1 + e^{-x}} = \frac{1 + e^{-x} - 1}{1 + e^{-x}} = 1 - \frac{1}{1 + e^{-x}} = 1 - \sigma(x)$$

–ü–æ—ç—Ç–æ–º—É: $\sigma'(x) = \sigma(x)(1 - \sigma(x))$

**–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã:**

–ü—Ä–∏ $x = 0$:
- $\sigma(0) = \frac{1}{1 + e^0} = \frac{1}{2} = 0.5$
- $\sigma'(0) = 0.5 \cdot (1 - 0.5) = 0.25$

–ü—Ä–∏ $x = 2$:
- $\sigma(2) = \frac{1}{1 + e^{-2}} \approx \frac{1}{1 + 0.135} \approx 0.881$
- $\sigma'(2) \approx 0.881 \cdot (1 - 0.881) \approx 0.105$

–ü—Ä–∏ $x = -2$:
- $\sigma(-2) = \frac{1}{1 + e^{2}} \approx \frac{1}{1 + 7.389} \approx 0.119$
- $\sigma'(-2) \approx 0.119 \cdot (1 - 0.119) \approx 0.105$

**–°–≤–æ–π—Å—Ç–≤–∞:**
- –î–∏–∞–ø–∞–∑–æ–Ω: $(0, 1)$ - –∏–¥–µ–∞–ª—å–Ω–æ –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
- –ú–æ–Ω–æ—Ç–æ–Ω–Ω–æ –≤–æ–∑—Ä–∞—Å—Ç–∞—é—â–∞—è
- –î–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–∞—è –≤—Å—é–¥—É
- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –≤ —Ç–æ—á–∫–µ $x = 0$
- –ü—Ä–æ–±–ª–µ–º–∞ –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –±–æ–ª—å—à–∏—Ö $|x|$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
import numpy as np
import matplotlib.pyplot as plt

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)

# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
x = np.linspace(-6, 6, 100)
y = sigmoid(x)
y_prime = sigmoid_derivative(x)

plt.figure(figsize=(10, 6))
plt.subplot(1, 2, 1)
plt.plot(x, y, 'b-', label='sigmoid(x)')
plt.grid(True)
plt.title('–°–∏–≥–º–æ–∏–¥–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è')
plt.xlabel('x')
plt.ylabel('sigmoid(x)')

plt.subplot(1, 2, 2)
plt.plot(x, y_prime, 'r-', label="sigmoid'(x)")
plt.grid(True)
plt.title('–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Å–∏–≥–º–æ–∏–¥—ã')
plt.xlabel('x')
plt.ylabel("sigmoid'(x)")

plt.tight_layout()
plt.show()
```

### ‚ö° ReLU (Rectified Linear Unit)

**–§—É–Ω–∫—Ü–∏—è:**
$$\text{ReLU}(x) = \max(0, x) = \begin{cases} 
x & \text{–µ—Å–ª–∏ } x > 0 \\
0 & \text{–µ—Å–ª–∏ } x \leq 0 
\end{cases}$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\frac{d}{dx}\text{ReLU}(x) = \begin{cases} 
1 & \text{–µ—Å–ª–∏ } x > 0 \\
0 & \text{–µ—Å–ª–∏ } x \leq 0 
\end{cases}$$

**–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã:**
- $\text{ReLU}(5) = 5$, $\text{ReLU}'(5) = 1$
- $\text{ReLU}(-3) = 0$, $\text{ReLU}'(-3) = 0$
- $\text{ReLU}(0)$ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ (–Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ –æ–±—ã—á–Ω–æ 0)

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–∞—è –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω–æ
- –ù–µ —Å—Ç—Ä–∞–¥–∞–µ—Ç –æ—Ç –∑–∞—Ç—É—Ö–∞—é—â–∏—Ö –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
- –°–ø–æ—Å–æ–±—Å—Ç–≤—É–µ—Ç —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–π
- –ë–∏–æ–ª–æ–≥–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–Ω–æ

**–ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏:**
- "–ú–µ—Ä—Ç–≤—ã–µ –Ω–µ–π—Ä–æ–Ω—ã" (–Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö –≤—Ö–æ–¥–∞—Ö)
- –ù–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä—É–µ–º–∞ –≤ –Ω—É–ª–µ
- –ú–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –≤–∑—Ä—ã–≤–∞—é—â–∏–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º

**–ú–µ—Ä—Ç–≤—ã–µ –Ω–µ–π—Ä–æ–Ω—ã - –ø–æ–¥—Ä–æ–±–Ω–æ:**
–ö–æ–≥–¥–∞ –≤—Å–µ –≤—Ö–æ–¥—ã –Ω–µ–π—Ä–æ–Ω–∞ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã, ReLU –≤—ã–¥–∞—ë—Ç 0, –∞ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Ç–æ–∂–µ 0. –¢–∞–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–æ–±—Ä–∞—Ç–∏–º—ã–º.

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
def relu(x):
    return np.maximum(0, x)

def relu_derivative(x):
    return (x > 0).astype(float)

# –ü—Ä–∏–º–µ—Ä —Å –º–∞—Å—Å–∏–≤–æ–º
x = np.array([-2, -1, 0, 1, 2])
print(f"ReLU({x}) = {relu(x)}")  # [0 0 0 1 2]
print(f"ReLU'({x}) = {relu_derivative(x)}")  # [0 0 0 1 1]

# –ü—Ä–∏–º–µ—Ä "–º–µ—Ä—Ç–≤–æ–≥–æ" –Ω–µ–π—Ä–æ–Ω–∞
weights = np.array([-1, -2, -3])
inputs = np.array([1, 2, 3])
output = np.dot(weights, inputs)  # -14
relu_output = relu(output)  # 0
grad = relu_derivative(output)  # 0 - –Ω–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π!
```

**–í–∞—Ä–∏–∞–Ω—Ç—ã ReLU:**
- **Leaky ReLU:** $f(x) = \max(\alpha x, x)$ –≥–¥–µ $\alpha = 0.01$
- **ELU:** $f(x) = \begin{cases} x & x \geq 0 \\ \alpha(e^x - 1) & x < 0 \end{cases}$
- **Swish:** $f(x) = x \cdot \sigma(x)$

### üåä Tanh (–≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å)

**–§—É–Ω–∫—Ü–∏—è:**
$$\tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} = \frac{e^{2x} - 1}{e^{2x} + 1}$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\frac{d}{dx}\tanh(x) = 1 - \tanh^2(x)$$

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π:**
–ü—É—Å—Ç—å $u = e^x - e^{-x}$ –∏ $v = e^x + e^{-x}$

–¢–æ–≥–¥–∞ $\tanh(x) = \frac{u}{v}$

$u' = e^x + e^{-x}$ –∏ $v' = e^x - e^{-x}$

–ü–æ –ø—Ä–∞–≤–∏–ª—É —á–∞—Å—Ç–Ω–æ–≥–æ:
$$\tanh'(x) = \frac{(e^x + e^{-x})(e^x + e^{-x}) - (e^x - e^{-x})(e^x - e^{-x})}{(e^x + e^{-x})^2}$$

$$= \frac{(e^x + e^{-x})^2 - (e^x - e^{-x})^2}{(e^x + e^{-x})^2}$$

$$= 1 - \frac{(e^x - e^{-x})^2}{(e^x + e^{-x})^2} = 1 - \tanh^2(x)$$

**–°–≤—è–∑—å —Å —Å–∏–≥–º–æ–∏–¥–æ–π:**
$$\tanh(x) = 2\sigma(2x) - 1$$

**–ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã:**

–ü—Ä–∏ $x = 0$:
- $\tanh(0) = \frac{1 - 1}{1 + 1} = 0$
- $\tanh'(0) = 1 - 0^2 = 1$

–ü—Ä–∏ $x = 1$:
- $\tanh(1) = \frac{e - e^{-1}}{e + e^{-1}} \approx \frac{2.718 - 0.368}{2.718 + 0.368} \approx 0.762$
- $\tanh'(1) = 1 - (0.762)^2 \approx 0.420$

–ü—Ä–∏ $x = -1$:
- $\tanh(-1) = -\tanh(1) \approx -0.762$ (–Ω–µ—á—ë—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è)
- $\tanh'(-1) = 1 - (-0.762)^2 \approx 0.420$

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–¥ —Å–∏–≥–º–æ–∏–¥–æ–π:**
- –î–∏–∞–ø–∞–∑–æ–Ω: $(-1, 1)$ –≤–º–µ—Å—Ç–æ $(0, 1)$
- –ù—É–ª–µ–≤–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –≤—ã—Ö–æ–¥–æ–≤ (–ª—É—á—à–µ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)
- –õ—É—á—à–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å
- –ù–µ—á—ë—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: $\tanh(-x) = -\tanh(x)$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
def tanh(x):
    return np.tanh(x)

def tanh_derivative(x):
    return 1 - np.tanh(x)**2

# –û–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
def tanh_manual(x):
    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))

# –ü—Ä–∏–º–µ—Ä
x = np.array([-2, -1, 0, 1, 2])
print(f"tanh({x}) = {tanh(x)}")  
print(f"tanh'({x}) = {tanh_derivative(x)}")

# –°–≤—è–∑—å —Å —Å–∏–≥–º–æ–∏–¥–æ–π
def tanh_via_sigmoid(x):
    return 2 * sigmoid(2*x) - 1

print(f"–ü—Ä–æ–≤–µ—Ä–∫–∞: {np.allclose(tanh(1), tanh_via_sigmoid(1))}")  # True
```

**–ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- –í —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö RNN –∏ LSTM
- –ö–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω—É–ª–µ–≤–æ–µ —Å—Ä–µ–¥–Ω–µ–µ
- –î–ª—è –º–∞–ª—ã—Ö —Å–µ—Ç–µ–π (–ª—É—á—à–µ —Å–∏–≥–º–æ–∏–¥—ã)

### üéØ Softmax

**–§—É–Ω–∫—Ü–∏—è (–¥–ª—è –≤–µ–∫—Ç–æ—Ä–∞):**
$$\text{softmax}(\mathbf{x})_i = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\frac{\partial \text{softmax}(\mathbf{x})_i}{\partial x_j} = \begin{cases}
\text{softmax}(\mathbf{x})_i (1 - \text{softmax}(\mathbf{x})_i) & \text{–µ—Å–ª–∏ } i = j \\
-\text{softmax}(\mathbf{x})_i \text{softmax}(\mathbf{x})_j & \text{–µ—Å–ª–∏ } i \neq j
\end{cases}$$

### üí® Leaky ReLU

**–§—É–Ω–∫—Ü–∏—è:**
$$\text{LeakyReLU}(x) = \begin{cases} 
x & \text{–µ—Å–ª–∏ } x > 0 \\
\alpha x & \text{–µ—Å–ª–∏ } x \leq 0 
\end{cases}$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\frac{d}{dx}\text{LeakyReLU}(x) = \begin{cases} 
1 & \text{–µ—Å–ª–∏ } x > 0 \\
\alpha & \text{–µ—Å–ª–∏ } x \leq 0 
\end{cases}$$

## üìâ –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –∏—Ö –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ

### üéØ –°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è –æ—à–∏–±–∫–∞ (MSE)

**–§—É–Ω–∫—Ü–∏—è:**
$$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—é:**
$$\frac{\partial \text{MSE}}{\partial \hat{y}_i} = \frac{2}{n}(\hat{y}_i - y_i)$$

### üìä –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è (–¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)

**–ë–∏–Ω–∞—Ä–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è:**
$$\text{BCE} = -\frac{1}{n} \sum_{i=1}^{n} [y_i \log(\hat{y}_i) + (1-y_i) \log(1-\hat{y}_i)]$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\frac{\partial \text{BCE}}{\partial \hat{y}_i} = -\frac{1}{n} \left[\frac{y_i}{\hat{y}_i} - \frac{1-y_i}{1-\hat{y}_i}\right]$$

**–ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–∞—è –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è:**
$$\text{CCE} = -\sum_{i=1}^{n} \sum_{j=1}^{k} y_{ij} \log(\hat{y}_{ij})$$

## üîÑ –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –æ—à–∏–±–∫–∏

### üéØ –û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è

**–¶–µ–ª—å:** –í—ã—á–∏—Å–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø–æ –≤—Å–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º —Å–µ—Ç–∏.

**–ü—Ä–∞–≤–∏–ª–æ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π:**
$$\frac{\partial L}{\partial w_{ij}^{(l)}} = \frac{\partial L}{\partial a_j^{(l)}} \cdot \frac{\partial a_j^{(l)}}{\partial z_j^{(l)}} \cdot \frac{\partial z_j^{(l)}}{\partial w_{ij}^{(l)}}$$

### üî¢ –û–±–æ–∑–Ω–∞—á–µ–Ω–∏—è

- $L$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
- $w_{ij}^{(l)}$ ‚Äî –≤–µ—Å –æ—Ç –Ω–µ–π—Ä–æ–Ω–∞ $i$ –∫ –Ω–µ–π—Ä–æ–Ω—É $j$ –Ω–∞ —Å–ª–æ–µ $l$
- $z_j^{(l)}$ ‚Äî –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –≤—Ö–æ–¥–æ–≤ –Ω–µ–π—Ä–æ–Ω–∞ $j$ –Ω–∞ —Å–ª–æ–µ $l$
- $a_j^{(l)}$ ‚Äî –∞–∫—Ç–∏–≤–∞—Ü–∏—è –Ω–µ–π—Ä–æ–Ω–∞ $j$ –Ω–∞ —Å–ª–æ–µ $l$
- $\delta_j^{(l)}$ ‚Äî –æ—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ–Ω–∞ $j$ –Ω–∞ —Å–ª–æ–µ $l$

### ‚ö° –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥

**–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–∞—Ü–∏–π:**
$$z_j^{(l)} = \sum_{i} w_{ij}^{(l)} a_i^{(l-1)} + b_j^{(l)}$$
$$a_j^{(l)} = f(z_j^{(l)})$$

### ‚¨ÖÔ∏è –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥

**–û—à–∏–±–∫–∞ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è:**
$$\delta_j^{(L)} = \frac{\partial L}{\partial a_j^{(L)}} \cdot f'(z_j^{(L)})$$

**–û—à–∏–±–∫–∞ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤:**
$$\delta_j^{(l)} = \left(\sum_{k} w_{jk}^{(l+1)} \delta_k^{(l+1)}\right) \cdot f'(z_j^{(l)})$$

**–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–µ—Å–æ–≤:**
$$\frac{\partial L}{\partial w_{ij}^{(l)}} = \delta_j^{(l)} \cdot a_i^{(l-1)}$$

**–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã —Å–º–µ—â–µ–Ω–∏–π:**
$$\frac{\partial L}{\partial b_j^{(l)}} = \delta_j^{(l)}$$

## üé≤ –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

### üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è

**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Å–æ–±—ã—Ç–∏—è:**
$$P(A) = \frac{\text{–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—ã—Ö –∏—Å—Ö–æ–¥–æ–≤}}{\text{–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ö–æ–¥–æ–≤}}$$

**–£—Å–ª–æ–≤–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å:**
$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

**–¢–µ–æ—Ä–µ–º–∞ –ë–∞–π–µ—Å–∞:**
$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

### üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è

**–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**
$$f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$$

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:**
$$f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}$$

### üìè –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ä—ã

**–°—Ä–µ–¥–Ω–µ–µ (–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ):**
$$E[X] = \mu = \frac{1}{n} \sum_{i=1}^{n} x_i$$

**–î–∏—Å–ø–µ—Ä—Å–∏—è:**
$$\text{Var}(X) = E[(X - \mu)^2] = \frac{1}{n} \sum_{i=1}^{n} (x_i - \mu)^2$$

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ:**
$$\sigma = \sqrt{\text{Var}(X)}$$

## üéØ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è

### üìâ –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫

**–ë–∞–∑–æ–≤–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ:**
$$\theta_{t+1} = \theta_t - \alpha \nabla_\theta J(\theta)$$

–≥–¥–µ:
- $\theta$ ‚Äî –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–≤–µ—Å–∞ –∏ —Å–º–µ—â–µ–Ω–∏—è)
- $\alpha$ ‚Äî —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (learning rate)
- $J(\theta)$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
- $\nabla_\theta J(\theta)$ ‚Äî –≥—Ä–∞–¥–∏–µ–Ω—Ç –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**
–ü—É—Å—Ç—å $J(w) = w^2 - 4w + 5$ (–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è)

1. **–í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç:**
   $$\frac{dJ}{dw} = 2w - 4$$

2. **–ù–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ:** $w_0 = 0$, $\alpha = 0.1$

3. **–ò—Ç–µ—Ä–∞—Ü–∏–∏:**
   - $w_1 = w_0 - \alpha \cdot \frac{dJ}{dw}|_{w_0} = 0 - 0.1 \cdot (2 \cdot 0 - 4) = 0 + 0.4 = 0.4$
   - $w_2 = 0.4 - 0.1 \cdot (2 \cdot 0.4 - 4) = 0.4 - 0.1 \cdot (-3.2) = 0.4 + 0.32 = 0.72$
   - $w_3 = 0.72 - 0.1 \cdot (2 \cdot 0.72 - 4) = 0.72 + 0.256 = 0.976$
   - ...
   - –ú–∏–Ω–∏–º—É–º: $w^* = 2$ (–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏)

**–¢–∏–ø—ã –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞:**

1. **Batch Gradient Descent:** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
   $$\theta_{t+1} = \theta_t - \alpha \frac{1}{m} \sum_{i=1}^{m} \nabla_\theta J(\theta, x^{(i)}, y^{(i)})$$

2. **Stochastic Gradient Descent (SGD):** –ø–æ –æ–¥–Ω–æ–º—É –ø—Ä–∏–º–µ—Ä—É
   $$\theta_{t+1} = \theta_t - \alpha \nabla_\theta J(\theta, x^{(i)}, y^{(i)})$$

3. **Mini-batch Gradient Descent:** –ø–æ –º–∞–ª—ã–º –±–∞—Ç—á–∞–º
   $$\theta_{t+1} = \theta_t - \alpha \frac{1}{|B|} \sum_{i \in B} \nabla_\theta J(\theta, x^{(i)}, y^{(i)})$$

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
import numpy as np
import matplotlib.pyplot as plt

def gradient_descent_example():
    # –§—É–Ω–∫—Ü–∏—è –∏ –µ—ë –≥—Ä–∞–¥–∏–µ–Ω—Ç
    def f(w):
        return w**2 - 4*w + 5
    
    def df_dw(w):
        return 2*w - 4
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    w = 0.0  # –Ω–∞—á–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    alpha = 0.1  # —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    num_iterations = 20
    
    history = []
    
    for i in range(num_iterations):
        grad = df_dw(w)
        w = w - alpha * grad
        loss = f(w)
        history.append((w, loss))
        print(f"–ò—Ç–µ—Ä–∞—Ü–∏—è {i+1}: w = {w:.4f}, loss = {loss:.4f}, grad = {grad:.4f}")
    
    return history

# –ó–∞–ø—É—Å–∫
history = gradient_descent_example()
```

**–ü—Ä–æ–±–ª–µ–º—ã –æ–±—ã—á–Ω–æ–≥–æ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞:**
- –ú–µ–¥–ª–µ–Ω–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–∞—Ö
- –ö–æ–ª–µ–±–∞–Ω–∏—è –≤ —É–∑–∫–∏—Ö –æ–≤—Ä–∞–≥–∞—Ö
- –°–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã–±–æ—Ä–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è

### ‚ö° Momentum (–ò–º–ø—É–ª—å—Å)

**–û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è:** –ù–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å "—Å–∫–æ—Ä–æ—Å—Ç—å" –¥–≤–∏–∂–µ–Ω–∏—è –ø–æ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –ø–æ—Ç–µ—Ä—å.

**–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –∏–º–ø—É–ª—å—Å–æ–º:**
$$v_t = \beta v_{t-1} + (1-\beta) \nabla_\theta J(\theta)$$
$$\theta_{t+1} = \theta_t - \alpha v_t$$

–≥–¥–µ:
- $v_t$ ‚Äî "—Å–∫–æ—Ä–æ—Å—Ç—å" –Ω–∞ —à–∞–≥–µ $t$
- $\beta$ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–º–ø—É–ª—å—Å–∞ (–æ–±—ã—á–Ω–æ 0.9)
- $v_0 = 0$ (–Ω–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å)

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**
–¢–∞ –∂–µ —Ñ—É–Ω–∫—Ü–∏—è $J(w) = w^2 - 4w + 5$, –Ω–æ —Å momentum:

1. $w_0 = 0$, $v_0 = 0$, $\alpha = 0.1$, $\beta = 0.9$
2. $\text{grad}_0 = 2 \cdot 0 - 4 = -4$
3. $v_1 = 0.9 \cdot 0 + 0.1 \cdot (-4) = -0.4$
4. $w_1 = 0 - 0.1 \cdot (-0.4) = 0.04$
5. $\text{grad}_1 = 2 \cdot 0.04 - 4 = -3.92$
6. $v_2 = 0.9 \cdot (-0.4) + 0.1 \cdot (-3.92) = -0.36 - 0.392 = -0.752$
7. $w_2 = 0.04 - 0.1 \cdot (-0.752) = 0.04 + 0.0752 = 0.1152$

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –£—Å–∫–æ—Ä—è–µ—Ç —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤ –Ω—É–∂–Ω–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏
- –£–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–µ–±–∞–Ω–∏—è
- –ú–æ–∂–µ—Ç –ø—Ä–æ—Å–∫–æ—á–∏—Ç—å –º–µ–ª–∫–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã

**–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```python
def momentum_optimizer():
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
    w = 0.0
    v = 0.0  # —Å–∫–æ—Ä–æ—Å—Ç—å
    alpha = 0.1
    beta = 0.9
    
    for i in range(20):
        grad = 2*w - 4  # –≥—Ä–∞–¥–∏–µ–Ω—Ç
        v = beta * v + (1 - beta) * grad  # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ—Å—Ç–∏
        w = w - alpha * v  # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        
        loss = w**2 - 4*w + 5
        print(f"–ò—Ç–µ—Ä–∞—Ü–∏—è {i+1}: w = {w:.4f}, v = {v:.4f}, loss = {loss:.4f}")
    
    return w

final_w = momentum_optimizer()
```

### üéØ Adam Optimizer (–ê–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã)

**–û—Å–Ω–æ–≤–Ω–∞—è –∏–¥–µ—è:** –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å momentum —Å –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç—å—é –æ–±—É—á–µ–Ω–∏—è.

**–ü–µ—Ä–≤—ã–π –º–æ–º–µ–Ω—Ç (—Å—Ä–µ–¥–Ω–µ–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤):**
$$m_t = \beta_1 m_{t-1} + (1-\beta_1) \nabla_\theta J(\theta)$$

**–í—Ç–æ—Ä–æ–π –º–æ–º–µ–Ω—Ç (—Å—Ä–µ–¥–Ω–µ–µ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤):**
$$v_t = \beta_2 v_{t-1} + (1-\beta_2) (\nabla_\theta J(\theta))^2$$

**–ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Å–º–µ—â–µ–Ω–∏—è:**
$$\hat{m}_t = \frac{m_t}{1-\beta_1^t}$$
$$\hat{v}_t = \frac{v_t}{1-\beta_2^t}$$

**–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤:**
$$\theta_{t+1} = \theta_t - \frac{\alpha}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t$$

**–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:**
- $\beta_1 = 0.9$ (–¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞)
- $\beta_2 = 0.999$ (–¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –º–æ–º–µ–Ω—Ç–∞)
- $\alpha = 0.001$ (—Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è)
- $\epsilon = 10^{-8}$ (–¥–ª—è —á–∏—Å–ª–æ–≤–æ–π —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)

**–ü–æ–¥—Ä–æ–±–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è:**
```
import numpy as np

class AdamOptimizer:
    def __init__(self, alpha=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):
        self.alpha = alpha
        self.beta1 = beta1
        self.beta2 = beta2
        self.epsilon = epsilon
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–º–µ–Ω—Ç–æ–≤
        self.m = 0  # –ø–µ—Ä–≤—ã–π –º–æ–º–µ–Ω—Ç
        self.v = 0  # –≤—Ç–æ—Ä–æ–π –º–æ–º–µ–Ω—Ç
        self.t = 0  # —Å—á—ë—Ç—á–∏–∫ —à–∞–≥–æ–≤
    
    def update(self, param, grad):
        self.t += 1
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–º–µ–Ω—Ç–æ–≤
        self.m = self.beta1 * self.m + (1 - self.beta1) * grad
        self.v = self.beta2 * self.v + (1 - self.beta2) * grad**2
        
        # –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Å–º–µ—â–µ–Ω–∏—è
        m_hat = self.m / (1 - self.beta1**self.t)
        v_hat = self.v / (1 - self.beta2**self.t)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        param_new = param - self.alpha * m_hat / (np.sqrt(v_hat) + self.epsilon)
        
        return param_new

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
def adam_example():
    optimizer = AdamOptimizer(alpha=0.01)
    w = 0.0
    
    for i in range(100):
        grad = 2*w - 4  # –≥—Ä–∞–¥–∏–µ–Ω—Ç —Ñ—É–Ω–∫—Ü–∏–∏ w^2 - 4w + 5
        w = optimizer.update(w, grad)
        
        if i % 10 == 0:
            loss = w**2 - 4*w + 5
            print(f"–ò—Ç–µ—Ä–∞—Ü–∏—è {i}: w = {w:.6f}, loss = {loss:.6f}")
    
    return w

final_w_adam = adam_example()
```

**–ü–æ—á–µ–º—É Adam —Ä–∞–±–æ—Ç–∞–µ—Ç –ª—É—á—à–µ:**
1. **–ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è:** –∫–∞–∂–¥—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –∏–º–µ–µ—Ç —Å–≤–æ—é —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å
2. **Momentum:** –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–µ–æ–¥–æ–ª–µ–≤–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–∏–Ω–∏–º—É–º—ã
3. **–ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Å–º–µ—â–µ–Ω–∏—è:** –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞—á–∞–ª—å–Ω—É—é –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å –∫ –Ω—É–ª—é
4. **–°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å:** —Ä–µ–¥–∫–æ —Ä–∞—Å—Ö–æ–¥–∏—Ç—Å—è

**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤:**
```python
def compare_optimizers():
    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    def f(w): return w**2 - 4*w + 5
    def df_dw(w): return 2*w - 4
    
    # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫
    w_gd = 0.0
    for _ in range(50):
        w_gd = w_gd - 0.1 * df_dw(w_gd)
    
    # Momentum
    w_mom, v = 0.0, 0.0
    for _ in range(50):
        grad = df_dw(w_mom)
        v = 0.9 * v + 0.1 * grad
        w_mom = w_mom - 0.1 * v
    
    # Adam
    adam = AdamOptimizer(alpha=0.1)
    w_adam = 0.0
    for _ in range(50):
        w_adam = adam.update(w_adam, df_dw(w_adam))
    
    print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—Å–ª–µ 50 –∏—Ç–µ—Ä–∞—Ü–∏–π:")
    print(f"GD: w = {w_gd:.6f}, loss = {f(w_gd):.6f}")
    print(f"Momentum: w = {w_mom:.6f}, loss = {f(w_mom):.6f}")
    print(f"Adam: w = {w_adam:.6f}, loss = {f(w_adam):.6f}")
    print(f"–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –º–∏–Ω–∏–º—É–º: w = 2.0, loss = 1.0")

compare_optimizers()
```

## üî¢ –ß–∏—Å–ª–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã

### üéØ –°—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π

**–°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å–æ—Ñ—Ç–º–∞–∫—Å:**
$$\text{softmax}(x_i) = \frac{e^{x_i - \max(x)}}{\sum_j e^{x_j - \max(x)}}$$

**–°—Ç–∞–±–∏–ª—å–Ω–∞—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è:**
$$\sigma(x) = \begin{cases}
\frac{1}{1 + e^{-x}} & \text{–µ—Å–ª–∏ } x \geq 0 \\
\frac{e^x}{1 + e^x} & \text{–µ—Å–ª–∏ } x < 0
\end{cases}$$

### üìä –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è

**Batch Normalization:**
$$\hat{x}_i = \frac{x_i - \mu_B}{\sqrt{\sigma_B^2 + \epsilon}}$$
$$y_i = \gamma \hat{x}_i + \beta$$

–≥–¥–µ:
- $\mu_B$ ‚Äî —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –±–∞—Ç—á—É
- $\sigma_B^2$ ‚Äî –¥–∏—Å–ø–µ—Ä—Å–∏—è –ø–æ –±–∞—Ç—á—É
- $\gamma, \beta$ ‚Äî –æ–±—É—á–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

## üé™ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

### üî¢ –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–≥–º–æ–∏–¥–∞

**–°–≤—è–∑—å —Å –≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–º —Ç–∞–Ω–≥–µ–Ω—Å–æ–º:**
$$\sigma(x) = \frac{1 + \tanh(x/2)}{2}$$

### üåä Swish (—Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏–µ)

**–§—É–Ω–∫—Ü–∏—è:**
$$\text{Swish}(x) = x \cdot \sigma(\beta x)$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è:**
$$\frac{d}{dx}\text{Swish}(x) = \sigma(\beta x) + x \cdot \sigma(\beta x)(1-\sigma(\beta x)) \cdot \beta$$

### ‚ö° GELU (Gaussian Error Linear Unit)

**–§—É–Ω–∫—Ü–∏—è:**
$$\text{GELU}(x) = x \cdot \Phi(x)$$

–≥–¥–µ $\Phi(x)$ ‚Äî —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.

**–ü—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ:**
$$\text{GELU}(x) \approx 0.5x\left(1 + \tanh\left(\sqrt{\frac{2}{\pi}}\left(x + 0.044715x^3\right)\right)\right)$$

## üéØ –ú–∞—Ç—Ä–∏—á–Ω–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ

### üìä –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ —Å–∫–∞–ª—è—Ä—É:**
$$\frac{\partial}{\partial x}(\mathbf{A}\mathbf{x}) = \mathbf{A}^T$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π —Ñ–æ—Ä–º—ã:**
$$\frac{\partial}{\partial \mathbf{x}}(\mathbf{x}^T\mathbf{A}\mathbf{x}) = (\mathbf{A} + \mathbf{A}^T)\mathbf{x}$$

**–ü—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è —Å–ª–µ–¥–∞:**
$$\frac{\partial}{\partial \mathbf{A}}\text{tr}(\mathbf{A}\mathbf{B}) = \mathbf{B}^T$$

### üîÑ –Ø–∫–æ–±–∏–∞–Ω

**–î–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ $\mathbf{f}: \mathbb{R}^n \to \mathbb{R}^m$:**
$$\mathbf{J} = \begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \cdots & \frac{\partial f_1}{\partial x_n} \\
\frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \cdots & \frac{\partial f_2}{\partial x_n} \\
\vdots & \vdots & \ddots & \vdots \\
\frac{\partial f_m}{\partial x_1} & \frac{\partial f_m}{\partial x_2} & \cdots & \frac{\partial f_m}{\partial x_n}
\end{bmatrix}$$

## üíª –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã

### üßÆ –ü—Ä–∏–º–µ—Ä: –ü—Ä–æ—Å—Ç–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å

**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:** –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (2 –Ω–µ–π—Ä–æ–Ω–∞) ‚Üí –°–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π (3 –Ω–µ–π—Ä–æ–Ω–∞) ‚Üí –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π (1 –Ω–µ–π—Ä–æ–Ω)

**–ü–æ–¥—Ä–æ–±–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø–æ—à–∞–≥–æ–≤—ã–º–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º–∏:**

```python
import numpy as np

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∏ –¥–∞–Ω–Ω—ã—Ö
np.random.seed(42)

# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å–µ—Ç–∏
input_size = 2
hidden_size = 3
output_size = 1

# –í–µ—Å–∞ (–º–∞–ª—ã–µ —Å–ª—É—á–∞–π–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
W1 = np.random.randn(hidden_size, input_size) * 0.5  # 3x2
b1 = np.zeros((hidden_size, 1))  # 3x1
W2 = np.random.randn(output_size, hidden_size) * 0.5  # 1x3
b2 = np.zeros((output_size, 1))  # 1x1

print("–ù–∞—á–∞–ª—å–Ω—ã–µ –≤–µ—Å–∞:")
print(f"W1 =\n{W1}")
print(f"b1 = {b1.flatten()}")
print(f"W2 = {W2}")
print(f"b2 = {b2.flatten()}")

# –ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    s = sigmoid(x)
    return s * (1 - s)

# –î–∞–Ω–Ω—ã–µ (XOR –∑–∞–¥–∞—á–∞)
X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T  # 2x4
y = np.array([[0, 1, 1, 0]])  # 1x4

print(f"\n–í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ X:\n{X}")
print(f"–¶–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è y: {y.flatten()}")

# –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
x_sample = X[:, 0:1]  # –ø–µ—Ä–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü [0, 0]
y_sample = y[:, 0:1]  # [0]

print(f"\n=== –ü–†–Ø–ú–û–ô –ü–†–û–•–û–î –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ {x_sample.flatten()} ===")

# –°–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π
z1 = np.dot(W1, x_sample) + b1
print(f"z1 = W1 @ x + b1 = {z1.flatten()}")

a1 = sigmoid(z1)
print(f"a1 = sigmoid(z1) = {a1.flatten()}")

# –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
z2 = np.dot(W2, a1) + b2
print(f"z2 = W2 @ a1 + b2 = {z2.flatten()}")

a2 = sigmoid(z2)
print(f"a2 = sigmoid(z2) = {a2.flatten()}")

# –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å (MSE)
loss = 0.5 * (y_sample - a2)**2
print(f"\n–ü–æ—Ç–µ—Ä—è: 0.5 * (y - a2)^2 = 0.5 * ({y_sample.flatten()[0]} - {a2.flatten()[0]})^2 = {loss.flatten()[0]:.6f}")

print(f"\n=== –û–ë–†–ê–¢–ù–´–ô –ü–†–û–•–û–î ===")

# –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ - –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
dL_da2 = -(y_sample - a2)  # –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è MSE
print(f"dL/da2 = -(y - a2) = {dL_da2.flatten()}")

da2_dz2 = sigmoid_derivative(z2)
print(f"da2/dz2 = sigmoid'(z2) = {da2_dz2.flatten()}")

delta2 = dL_da2 * da2_dz2
print(f"delta2 = dL/da2 * da2/dz2 = {delta2.flatten()}")

# –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–µ—Å–æ–≤ –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è
dW2 = np.dot(delta2, a1.T)
print(f"dW2 = delta2 @ a1.T = {dW2}")

db2 = delta2
print(f"db2 = delta2 = {db2.flatten()}")

# –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥ - —Å–∫—Ä—ã—Ç—ã–π —Å–ª–æ–π
dL_da1 = np.dot(W2.T, delta2)
print(f"dL/da1 = W2.T @ delta2 = {dL_da1.flatten()}")

da1_dz1 = sigmoid_derivative(z1)
print(f"da1/dz1 = sigmoid'(z1) = {da1_dz1.flatten()}")

delta1 = dL_da1 * da1_dz1
print(f"delta1 = dL/da1 * da1/dz1 = {delta1.flatten()}")

# –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –≤–µ—Å–æ–≤ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è
dW1 = np.dot(delta1, x_sample.T)
print(f"dW1 =\n{dW1}")

db1 = delta1
print(f"db1 = {db1.flatten()}")

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
learning_rate = 0.5
print(f"\n=== –û–ë–ù–û–í–õ–ï–ù–ò–ï –í–ï–°–û–í (lr = {learning_rate}) ===")

W2_new = W2 - learning_rate * dW2
print(f"W2_new = W2 - lr * dW2 = {W2_new}")

b2_new = b2 - learning_rate * db2
print(f"b2_new = {b2_new.flatten()}")

W1_new = W1 - learning_rate * dW1
print(f"W1_new =\n{W1_new}")

b1_new = b1 - learning_rate * db1
print(f"b1_new = {b1_new.flatten()}")
```

### üéØ –ü—Ä–∏–º–µ—Ä: Softmax —Å –∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–µ–π

**–ü–æ–¥—Ä–æ–±–Ω—ã–π –ø—Ä–∏–º–µ—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –Ω–∞ 3 –∫–ª–∞—Å—Å–∞:**

```python
import numpy as np

def stable_softmax(x):
    """–ß–∏—Å–ª–µ–Ω–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è softmax"""
    exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))
    return exp_x / np.sum(exp_x, axis=0, keepdims=True)

def cross_entropy_loss(y_true, y_pred):
    """–ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å"""
    # –ò–∑–±–µ–≥–∞–µ–º log(0)
    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)
    return -np.sum(y_true * np.log(y_pred))

# –ü—Ä–∏–º–µ—Ä: 3 –∫–ª–∞—Å—Å–∞, 4 –ø—Ä–∏–º–µ—Ä–∞
logits = np.array([
    [2.0, 1.0, 0.1],    # –ø—Ä–∏–º–µ—Ä 1
    [1.0, 3.0, 0.2],    # –ø—Ä–∏–º–µ—Ä 2  
    [0.1, 0.2, 2.5],    # –ø—Ä–∏–º–µ—Ä 3
    [1.5, 1.5, 1.5]     # –ø—Ä–∏–º–µ—Ä 4
]).T  # 3x4 (–∫–ª–∞—Å—Å—ã x –ø—Ä–∏–º–µ—Ä—ã)

# –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (one-hot encoding)
y_true = np.array([
    [1, 0, 0, 0],  # –∫–ª–∞—Å—Å 0
    [0, 1, 0, 0],  # –∫–ª–∞—Å—Å 1
    [0, 0, 1, 1]   # –∫–ª–∞—Å—Å 2
])  # 3x4

print("–õ–æ–≥–∏—Ç—ã (–¥–æ softmax):")
print(logits)
print("\n–ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏:")
print(y_true)

# –ü—Ä–∏–º–µ–Ω—è–µ–º softmax
y_pred = stable_softmax(logits)
print("\n–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ softmax:")
print(y_pred)
print("\n–ü—Ä–æ–≤–µ—Ä–∫–∞ (—Å—É–º–º–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º):")
print(np.sum(y_pred, axis=0))  # –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å [1, 1, 1, 1]

# –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ—Ä–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞
losses = []
for i in range(4):
    loss = cross_entropy_loss(y_true[:, i:i+1], y_pred[:, i:i+1])
    losses.append(loss)
    print(f"–ü—Ä–∏–º–µ—Ä {i+1}: –ø–æ—Ç–µ—Ä—è = {loss:.4f}")

avg_loss = np.mean(losses)
print(f"\n–°—Ä–µ–¥–Ω—è—è –ø–æ—Ç–µ—Ä—è: {avg_loss:.4f}")

# –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
print("\n=== –ì–†–ê–î–ò–ï–ù–¢–´ ===")
print("–î–ª—è softmax + cross-entropy: dL/dz = y_pred - y_true")
gradients = y_pred - y_true
print("–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–æ –ª–æ–≥–∏—Ç–∞–º:")
print(gradients)

# –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
print("\n–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤:")
for i in range(4):
    predicted_class = np.argmax(y_pred[:, i])
    true_class = np.argmax(y_true[:, i])
    confidence = y_pred[true_class, i]
    
    print(f"–ü—Ä–∏–º–µ—Ä {i+1}:")
    print(f"  –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {predicted_class}")
    print(f"  –ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å: {true_class}")
    print(f"  –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –∫–ª–∞—Å—Å–µ: {confidence:.4f}")
    print(f"  –ì—Ä–∞–¥–∏–µ–Ω—Ç –¥–ª—è –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞: {gradients[true_class, i]:.4f}")
```

### üîÑ –ü—Ä–∏–º–µ—Ä: –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏

**–û–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö XOR —Å –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ—Ü–µ—Å—Å–∞:**

```python
import numpy as np
import matplotlib.pyplot as plt

class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.5):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤
        self.W1 = np.random.randn(hidden_size, input_size) * 0.5
        self.b1 = np.zeros((hidden_size, 1))
        self.W2 = np.random.randn(output_size, hidden_size) * 0.5
        self.b2 = np.zeros((output_size, 1))
        self.lr = learning_rate
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.loss_history = []
    
    def sigmoid(self, x):
        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))
    
    def sigmoid_derivative(self, x):
        s = self.sigmoid(x)
        return s * (1 - s)
    
    def forward(self, X):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è backprop
        self.z1 = np.dot(self.W1, X) + self.b1
        self.a1 = self.sigmoid(self.z1)
        self.z2 = np.dot(self.W2, self.a1) + self.b2
        self.a2 = self.sigmoid(self.z2)
        return self.a2
    
    def backward(self, X, y, output):
        m = X.shape[1]  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤
        
        # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
        dz2 = output - y
        dW2 = (1/m) * np.dot(dz2, self.a1.T)
        db2 = (1/m) * np.sum(dz2, axis=1, keepdims=True)
        
        da1 = np.dot(self.W2.T, dz2)
        dz1 = da1 * self.sigmoid_derivative(self.z1)
        dW1 = (1/m) * np.dot(dz1, X.T)
        db1 = (1/m) * np.sum(dz1, axis=1, keepdims=True)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
        self.W2 -= self.lr * dW2
        self.b2 -= self.lr * db2
        self.W1 -= self.lr * dW1
        self.b1 -= self.lr * db1
    
    def train(self, X, y, epochs=1000, verbose=True):
        for epoch in range(epochs):
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            output = self.forward(X)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
            loss = np.mean((y - output)**2)
            self.loss_history.append(loss)
            
            # –û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥
            self.backward(X, y, output)
            
            # –í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            if verbose and epoch % 100 == 0:
                accuracy = np.mean((output > 0.5) == (y > 0.5))
                print(f"–≠–ø–æ—Ö–∞ {epoch}: –ü–æ—Ç–µ—Ä—è = {loss:.6f}, –¢–æ—á–Ω–æ—Å—Ç—å = {accuracy:.4f}")
    
    def predict(self, X):
        return self.forward(X)

# –î–∞–Ω–Ω—ã–µ XOR
X = np.array([[0, 0, 1, 1], [0, 1, 0, 1]])
y = np.array([[0, 1, 1, 0]])

print("–î–∞–Ω–Ω—ã–µ XOR:")
print(f"X =\n{X}")
print(f"y = {y.flatten()}")

# –°–æ–∑–¥–∞–Ω–∏–µ –∏ –æ–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏
nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1, learning_rate=1.0)

print("\n–û–±—É—á–µ–Ω–∏–µ —Å–µ—Ç–∏...")
nn.train(X, y, epochs=2000, verbose=True)

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
print("\n=== –†–ï–ó–£–õ–¨–¢–ê–¢–´ ===")
predictions = nn.predict(X)
for i in range(4):
    x_vals = X[:, i]
    true_val = y[0, i]
    pred_val = predictions[0, i]
    pred_class = 1 if pred_val > 0.5 else 0
    
    print(f"–í—Ö–æ–¥: {x_vals}, –û–∂–∏–¥–∞–µ—Ç—Å—è: {true_val}, –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ: {pred_val:.4f} ‚Üí {pred_class}")

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(nn.loss_history)
plt.title('–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è')
plt.xlabel('–≠–ø–æ—Ö–∞')
plt.ylabel('MSE Loss')
plt.grid(True)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ —Ä–µ—à–µ–Ω–∏—è
plt.subplot(1, 2, 2)
xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 100), np.linspace(-0.5, 1.5, 100))
grid_points = np.c_[xx.ravel(), yy.ravel()].T
Z = nn.predict(grid_points)
Z = Z.reshape(xx.shape)

plt.contour(xx, yy, Z, levels=[0.5], colors='red', linestyles='--', linewidths=2)
plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')
plt.colorbar(label='–í—ã—Ö–æ–¥ —Å–µ—Ç–∏')

# –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö
colors = ['blue', 'red']
for i in range(4):
    plt.scatter(X[0, i], X[1, i], c=colors[int(y[0, i])], s=100, edgecolors='black')
    plt.annotate(f'({X[0,i]},{X[1,i]})‚Üí{y[0,i]}', (X[0, i], X[1, i]), 
                xytext=(5, 5), textcoords='offset points')

plt.title('–ì—Ä–∞–Ω–∏—Ü–∞ —Ä–µ—à–µ–Ω–∏—è XOR')
plt.xlabel('x1')
plt.ylabel('x2')
plt.grid(True)

plt.tight_layout()
plt.show()

print(f"\n–§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ—Ç–µ—Ä—è: {nn.loss_history[-1]:.8f}")
print(f"–¢–æ—á–Ω–æ—Å—Ç—å: {np.mean((predictions > 0.5) == (y > 0.5)) * 100:.1f}%")
```

## üîó –°–≤—è–∑–∞–Ω–Ω—ã–µ —Ç–µ–º—ã

- [[–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫]] ‚Äî –ê–ª–≥–æ—Ä–∏—Ç–º—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
- [[–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä]] ‚Äî –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–∏–≥–º–æ–∏–¥–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
- [[–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∏ –Ω–µ–¥–æ–æ–±—É—á–µ–Ω–∏–µ]] ‚Äî –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è –∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
- [[üß≠ ML Navigation]] ‚Äî –í–µ—Ä–Ω—É—Ç—å—Å—è –∫ –Ω–∞–≤–∏–≥–∞—Ü–∏–∏

## üí° –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ:** –°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏ (PyTorch, TensorFlow) –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª—è—é—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
2. **–ß–∏—Å–ª–µ–Ω–Ω–∞—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å:** –í—Å–µ–≥–¥–∞ —É—á–∏—Ç—ã–≤–∞–π—Ç–µ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ –∏ –ø–æ—Ç–µ—Ä—é —Ç–æ—á–Ω–æ—Å—Ç–∏
3. **–í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:** –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∞—Ç—Ä–∏—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–º–µ—Å—Ç–æ —Ü–∏–∫–ª–æ–≤
4. **–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è:** –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Å–æ–≤ –∫—Ä–∏—Ç–∏—á–Ω–∞ –¥–ª—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
5. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:** –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ö–æ–¥–æ–≤ –∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ

#ml #mathematics #neural-networks #derivatives #matrices