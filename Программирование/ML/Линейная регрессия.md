**Цель**
цель линейной регресси состоит в том, чтобы построить прямую проходящую как можно ближе к точками(это данные в признаковом пространстве я бы описал их так)

![[Pasted image 20250909222323.png]]

![[Pasted image 20250909222344.png]]
Пример линейной регррессии 
![[Pasted image 20250909221342.png]]

![[Pasted image 20250909221437.png]]
### Базовый подход
Он заключается в том, чтобы если прямая ниже нужного значения, тогда мы добаввляем небольшую случайную сумму к *y-пересенению* и к весу формулы. В противном слуяае все работает оборатно
![[Pasted image 20250909222710.png]]
### **Квадратичный подход**
Вся суть в том чтобы найти правильное значение со знаком + или - и длобавить его к наклону и *Y-пересечению*. Суть в том чтобы добавлять разность точки и той точки что была спрогнозирована.
![[Pasted image 20250909223218.png]]
### Абсолютный подход
Суть в том чтобы свести все к одному случаю проверяется разность p - p', и если точка назодится над прямой, тогда добавляет n к наклону, иначе убавляем
![[Pasted image 20250909223539.png]]
### Алгоритм
Входный данные для алгоритма: 1) набор признкаов, 2) список их меток 3) маленькая величина на котрую нужно делать сдвиги
Сам алгоритм довльно простой, мы задаем случайный базовые числа для Y-перечения(костанты в формуле) и для наклона, после чего чер for с большим количеством итереций проделываем простую операцию
1) берем рандомный  признак
2) Применяем квадратичный метод и так по гругу
3) выводим граффик
![[Pasted image 20250910005930.png]]