### 1. Понятие функции потерь. Примеры функций потерь для задач регрессии и классификации.

Функция потерь это такая функция с помощью которой можно определить насколько сильно отличается полученный результат от того что должно получиться. С помощью нее, можно посчитать градиент, который покажет как каждый вес с параметром влияет на функцию патерь и пойти в сторону уиеньшения функции потерь, с помощью чего улучшается предсказания. Функция потерь одна из важнейших состовляющих ML, на ней держится метод обратного распрространения, с помощью которого происходит обучение сети. Также Функция потерь должна быть дефиринцируема и непрерывна.
Примеры функции потерь:
1. MSE
2. абсолютная ошибка
3. Кроссэнтропия
4. BCE
==Нужно тут напистаь формулы==
### 2. Градиентный спуск: идея, математическая формулировка, варианты (SGD, mini-batch, Adam).
Градиентный спуск - метод с помощью которого сеть обучается подбирая свои коэффиценты путем нахождения градиента функции потерь.
<span style="background:#fff88f">Формула градиентного спуска</span>
Одни из самых популярныйх и ихвестных примеров град спуска является:
SGD - суть заключается в том чтобы брать один случайный элемент из выборки пропускать его через сеть и считать функцию ошибку и подбивать на этой основе веса, после чего сделать так N(количество пример)=1 эпоха
Mini batch - суть в том чтобы вмсето обычно sgd где мы берем один случайный жлемент из выборки, разделить эту выборку на какоето количество подвыборок, по которым уже считать результат и loss function после чего делать обратно рапсрростронение и улучшать сеть
Adam - это один из самых популярных на данный момент оптимизаторов который базируется на логике двух другиз популяных оптимизатарах. Это SGD с Momentumom у которого взята логика по тому чтобы накапливать импульс и продолевать седловые точки, так и оптимизатора RMSProp (суть это оптимизатора заключается в том чтобы сделай learning rate для каждого веса уникальным, условно оптимизатор смотрит с помощью жкспонинциально скользящего среднего на то какой обычно градиент у этого параметра, если часто большой, для него лучше сделать шаг поменьше, если часто мальшенький, то шаг лучше сдлеать побольше)
Rpop - его суть заключается в том мы смотрим на знак градиента, мы умножаем градиенты, и если после переумножения получилось > 0 *положительное*, значит мы не пропустили ничего и можно даже немного ускориться и увеличить Learning Rate, а в обратном случае уменьишть LE в случае если знак поменялся.
### 3. Алгоритм обратного распространения ошибки (backpropagation). Правило цепочки дифференцирования сложной функции и его роль в backprop.
Суть bcakpropagetion заключается в том чтобы посчитать функцию ошибки, и дальше с помощью назождения вектора частных производных понять как каждый параметр влияет на рост функции, после чего взять анти градиент и сложить его с текущими весами
### 4. Матричные и тензорные операции в нейронных сетях. Почему они важны для эффективных вычислений?
Потому что нейронная сеть работает с числами а не с картинками или словами например. Если разбироть сверточные нейроные сети, то картинку представляется в формате матрицы с числами, при MLP мы делаем числовой вектр, который уже умножается на матрицу весов + байс
Потому что все держится на линейныз преобразования и тензорах
### 5. <span style="background:#fff88f">Принципы построения и обучения глубоких сетей.</span>
<span style="background:#fff88f">Глубокая сеть строится из нескольких слоев, слоев с линейными преобразованиями и слоями с нелинейным преобразованием</span>

### 6. <span style="background:#affad1">Архитектура многослойного персептрона: входной, скрытые и выходной слои.</span>
<span style="background:#affad1">Многослойный персептрон представляет собой сборище нескольки персетронов</span>
<span style="background:#affad1">в каждом слое есть сумматор и функция активация и в дальнейшем выход этого слое идет на вход следующему</span>
### 7. Универсальная аппроксимационная теорема (теорема Цыбенко). Её значение и ограничения.
Теорма цыбенко заключается в том что если взять сеьт и одно скрытого слоя с хорошей функцие активацией и если будет достаточно много нейронов, то существует такя сеть которая соет лешить и апроксимировать любую задачку
### 8. Роль нелинейности в скрытых слоях MLP. Что произойдёт, если использовать только линейные активации?
<span style="background:#affad1">Если использовта только линейные активации это будет приравниват ся к тому что сеть могла бы просто состоять из одного лсоя линейного преобразования, поНелинейные функции активации (ReLU, sigmoid, tanh и др.) в скрытых слоях нужны для того, чтобы:</span>

<span style="background:#affad1">- модель могла **изучать сложные, нелинейные зависимости** между входами и выходами;</span>
<span style="background:#affad1">- сеть перестала быть просто линейной моделью и получила **выразительную способность**;</span>
<span style="background:#affad1">- MLP мог аппроксимировать сложные функции (в том числе по теореме Цыбенко).</span>
<span style="background:#affad1">Без нелинейности сеть не может моделировать кривые, границы сложной формы и составные закономерности.</span>

### 9. Матричное исчисление, обобщение «правила цепочки» на многослойную структуру, Softmax-функция, категориальная кросс-энтропия.
В нейронных сетях вс представлено в виде тензоров разных размеров, что позволяет:
- позволяет компактно и эффективно вычислять сразу много операций,
- даёт возможность использовать оптимизации на GPU/TPU,
- выражает операции через стандартные линейные алгебраические конструкции,
- ускоряет обучение и вывод моделей.

![[Pasted image 20251215175021.png]]